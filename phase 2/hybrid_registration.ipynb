{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. fix/examine displacement vector math\n",
    "# 2. perhaps establish the colour map over the net displacement from image 0 -> image nf\n",
    "# 3. look at combining multiple feature algorithms eg edge detection, region segmentation\n",
    "# 4. find more data for deep learning model\n",
    "# 5. establish a few more optical flow algorithms to attempt to average out/improve precision of displacement vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "de032f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "from PIL import Image, ImageTk\n",
    "import fitz  \n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce850c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This section is designed to optimise image pre-processing \n",
    "Aims:\n",
    "- manage sequential images and folder structure such that sequence is easily retained\n",
    "- perform visual/mathematical filtering to refine image contrast and enable the subsequent algorithm\n",
    "- denoising the image (speckle decorrelation?)\n",
    "- contrast enhancement\n",
    "- motion artifact correction?\n",
    "'''\n",
    "# input variable is a folder containing png images in chronological order for now.\n",
    "def preprocess_image_sequence(image_sequence):\n",
    "\n",
    "    # create a dir for sequential preprocessed images\n",
    "    if not os.path.exists(\"denoised_sequence\"):\n",
    "        os.makedirs(\"denoised_sequence\")\n",
    "    if not os.path.exists(\"contrasted_sequence\"):\n",
    "        os.makedirs(\"contrasted_sequence\")\n",
    "    if not os.path.exists(\"preprocessed_sequence\"):\n",
    "        os.makedirs(\"preprocessed_sequence\")\n",
    "\n",
    "    # sort image paths from input folder\n",
    "    image_paths = sorted(glob(os.path.join(image_sequence, \"*.png\")))\n",
    "\n",
    "    # read first image as the reference image\n",
    "    reference_image = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # read in current image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # denoise image via median filtering \n",
    "        denoised_image = cv2.medianBlur(image, 3)\n",
    "        output_path = os.path.join(\"denoised_sequence\", f\"{idx:03d}.png\")\n",
    "        cv2.imwrite(output_path, denoised_image)\n",
    "\n",
    "        # contrast enhancement via adaptive histogram equalisation\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced_image = clahe.apply(denoised_image)\n",
    "        output_path = os.path.join(\"contrasted_sequence\", f\"{idx:03d}.png\")\n",
    "        cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "        # motion artifact correction or rigid alignment of current image to the reference image\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        _, warp_matrix = cv2.findTransformECC(reference_image, enhanced_image, warp_matrix, cv2.MOTION_EUCLIDEAN)\n",
    "\n",
    "        corrected_image = cv2.warpAffine(enhanced_image, warp_matrix, (enhanced_image.shape[1], enhanced_image.shape[0]),\n",
    "                                         flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        output_path = os.path.join(\"preprocessed_sequence\", f\"{idx:03d}.png\")\n",
    "        cv2.imwrite(output_path, corrected_image)\n",
    "\n",
    "    # Visualize the steps\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "    images = [image, denoised_image, enhanced_image, corrected_image]\n",
    "    titles = ['Original', 'Denoised', 'Contrast Enhanced', 'Motion Corrected']\n",
    "\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"preprocessing_pipeline\")\n",
    "\n",
    "# a simplified single image process for utilisation by the tkinter \n",
    "def preprocess_single_image(img, reference_img=None):\n",
    "    steps = {}\n",
    "\n",
    "    # Step 1: Original\n",
    "    steps['Original'] = img.copy()\n",
    "\n",
    "    # Step 2: Denoising\n",
    "    denoised = cv2.medianBlur(img, 3)\n",
    "    steps['Denoised'] = denoised\n",
    "\n",
    "    # Step 3: Contrast Enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    steps['Contrast Enhanced'] = enhanced\n",
    "\n",
    "    # Step 4: Motion Artifact Correction\n",
    "    if reference_img is not None:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        try:\n",
    "            _, warp_matrix = cv2.findTransformECC(reference_img, enhanced, warp_matrix, cv2.MOTION_EUCLIDEAN)\n",
    "            corrected = cv2.warpAffine(enhanced, warp_matrix, (enhanced.shape[1], enhanced.shape[0]),\n",
    "                                       flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        except cv2.error:\n",
    "            corrected = enhanced.copy()  # fallback if ECC fails\n",
    "    else:\n",
    "        corrected = enhanced.copy()\n",
    "\n",
    "    steps['Motion Corrected'] = corrected\n",
    "\n",
    "    return steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d3745bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The purpose of this section is to test combinations of several tracking algorithms into a single, hybrid methodology\n",
    "Aims:\n",
    "- building a combined hybrid methodology which factors the strengths of each algorithm\n",
    "- tweaking the influence or 'strength' of each algorithm based on overall model performance\n",
    "- perhaps model efficiency optimisation\n",
    "'''\n",
    "\n",
    "# optical tracking implementation\n",
    "'''\n",
    "Meant to target larger homogeneous regions of the tissue (areas of similar contrast)\n",
    "'''\n",
    "def optical_tracking():\n",
    "    return 0\n",
    "\n",
    "# feature based alignment implementation\n",
    "'''\n",
    "Meant to target tissue landmarks and structures\n",
    "need to test some segmentation algorithms and maybe combine to form an OCT optimal strategy\n",
    "'''\n",
    "def feature_alignment():\n",
    "    return 0\n",
    "\n",
    "# deep learning fine-tuning tracking implementation\n",
    "'''\n",
    "Uses a library of labelled imagery to make tracking adjustments\n",
    "not sure yet on method of implementation, probably looking at CNN\n",
    "'''\n",
    "def CNN():\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fdb5103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Base Page Class ===\n",
    "class Page(tk.Frame):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "\n",
    "# === Individual Pages ===\n",
    "class HomePage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        label = ttk.Label(self, text=\"Welcome to the OCT Deformation Tracking Suite\", font=(\"Helvetica\", 18))\n",
    "        label.pack(pady=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c4f41895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PreprocessingPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "\n",
    "        # --- Controls Bar ---\n",
    "        ctrl = ttk.Frame(self)\n",
    "        ctrl.pack(fill='x', pady=10)\n",
    "        ttk.Button(ctrl, text=\"Select Input Folder\", command=self.load_images)\\\n",
    "            .pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Previous\", command=self.prev_image)\\\n",
    "            .pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Next\", command=self.next_image)\\\n",
    "            .pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Reorder…\", command=self.open_reorder_dialog)\\\n",
    "            .pack(side='left', padx=5)\n",
    "\n",
    "        # --- Canvas for display ---\n",
    "        self.canvas = tk.Canvas(self, bg='#f0f0f0')\n",
    "        self.canvas.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "\n",
    "        # --- Internal State ---\n",
    "        self.entries = []            # list of (name, np.ndarray) in extraction order\n",
    "        self.images = []             # just the image arrays\n",
    "        self.reference_img = None\n",
    "        self.index = 0\n",
    "        self.preprocessed_steps = [] # list of dicts per image\n",
    "        self.tk_imgs = {}            # cache of PhotoImage for canvas\n",
    "\n",
    "    def preprocess_single_image(self, img, reference_img=None):\n",
    "        steps = {'Original': img.copy()}\n",
    "        steps['Denoised'] = cv2.medianBlur(img, 3)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        steps['Contrast Enhanced'] = clahe.apply(steps['Denoised'])\n",
    "        if reference_img is not None:\n",
    "            M = np.eye(2,3, dtype=np.float32)\n",
    "            try:\n",
    "                _, M = cv2.findTransformECC(reference_img, steps['Contrast Enhanced'], M,\n",
    "                                            cv2.MOTION_EUCLIDEAN)\n",
    "                steps['Motion Corrected'] = cv2.warpAffine(\n",
    "                    steps['Contrast Enhanced'], M,\n",
    "                    (img.shape[1], img.shape[0]),\n",
    "                    flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP\n",
    "                )\n",
    "            except cv2.error:\n",
    "                steps['Motion Corrected'] = steps['Contrast Enhanced'].copy()\n",
    "        else:\n",
    "            steps['Motion Corrected'] = steps['Contrast Enhanced'].copy()\n",
    "        return steps\n",
    "\n",
    "    def load_images(self):\n",
    "        src_folder = filedialog.askdirectory(title=\"Select Input Folder\")\n",
    "        if not src_folder:\n",
    "            return\n",
    "\n",
    "        out_folder = os.path.join(src_folder, \"extracted_OCT\")\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "        # clear old\n",
    "        import glob\n",
    "        for old in glob.glob(os.path.join(out_folder, \"*.png\")):\n",
    "            os.remove(old)\n",
    "\n",
    "        self.entries = []\n",
    "        seq_idx = 0   # visitation counter\n",
    "\n",
    "        for fname in os.listdir(src_folder):\n",
    "            if \"OCT\" not in fname.upper():\n",
    "                continue\n",
    "            path = os.path.join(src_folder, fname)\n",
    "            ext  = os.path.splitext(fname)[1].upper()\n",
    "\n",
    "            if ext == \".PDF\":\n",
    "                doc = fitz.open(path)\n",
    "                for pnum, page in enumerate(doc):\n",
    "                    for img_idx, img_info in enumerate(page.get_images(full=True)):\n",
    "                        if img_idx != 1:\n",
    "                            continue\n",
    "                        xref     = img_info[0]\n",
    "                        img_dict = doc.extract_image(xref)\n",
    "                        pil_img  = Image.open(io.BytesIO(img_dict[\"image\"])).convert(\"L\")\n",
    "                        arr      = np.array(pil_img)\n",
    "\n",
    "                        # name with sequence index\n",
    "                        base_name = f\"{seq_idx:03d}_{os.path.splitext(fname)[0]}_p{pnum+1}_i{img_idx}.png\"\n",
    "                        pil_img.save(os.path.join(out_folder, base_name), \"PNG\")\n",
    "                        self.entries.append((base_name, arr))\n",
    "                        seq_idx += 1\n",
    "                doc.close()\n",
    "\n",
    "            elif ext in (\".PNG\", \".JPG\", \".JPEG\", \".TIF\", \".TIFF\"):\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                pil_img  = Image.fromarray(img)\n",
    "                base_name = f\"{seq_idx:03d}_{os.path.splitext(fname)[0]}.png\"\n",
    "                pil_img.save(os.path.join(out_folder, base_name), \"PNG\")\n",
    "                self.entries.append((base_name, img))\n",
    "                seq_idx += 1\n",
    "\n",
    "        if not self.entries:\n",
    "            messagebox.showwarning(\"No OCT Images\",\n",
    "                                   \"No files with 'OCT' found in the selected folder.\")\n",
    "            return\n",
    "\n",
    "        # now rebuild images/preprocessing\n",
    "        self._rebuild_images_and_steps()\n",
    "        self.index = 0\n",
    "        self.show_current_image()\n",
    "\n",
    "\n",
    "    def _rebuild_images_and_steps(self):\n",
    "        # Called after load or after reorder\n",
    "        self.images = [arr for (name, arr) in self.entries]\n",
    "        self.reference_img = self.images[0]\n",
    "        self.preprocessed_steps = [\n",
    "            self.preprocess_single_image(img, self.reference_img)\n",
    "            for img in self.images\n",
    "        ]\n",
    "\n",
    "    def show_current_image(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        if not self.preprocessed_steps:\n",
    "            return\n",
    "        steps = self.preprocessed_steps[self.index]\n",
    "        for i, (title, img) in enumerate(steps.items()):\n",
    "            thumb  = Image.fromarray(img).resize((220,220))\n",
    "            tk_img = ImageTk.PhotoImage(thumb)\n",
    "            self.tk_imgs[i] = tk_img\n",
    "            x = 10 + i*240\n",
    "            self.canvas.create_image(x,10,anchor='nw',image=tk_img)\n",
    "            self.canvas.create_text(x+110,240,text=title,font=(\"Helvetica\",12))\n",
    "\n",
    "    def next_image(self):\n",
    "        if self.index < len(self.images)-1:\n",
    "            self.index += 1\n",
    "            self.show_current_image()\n",
    "\n",
    "    def prev_image(self):\n",
    "        if self.index>0:\n",
    "            self.index -= 1\n",
    "            self.show_current_image()\n",
    "\n",
    "    def open_reorder_dialog(self):\n",
    "        \"\"\"Open a small dialog to let the user drag images up/down in self.entries.\"\"\"\n",
    "        dlg = tk.Toplevel(self)\n",
    "        dlg.title(\"Reorder OCT Frames\")\n",
    "        dlg.grab_set()\n",
    "\n",
    "        lb = tk.Listbox(dlg, height= min(10, len(self.entries)), width=40)\n",
    "        lb.pack(side='left', fill='y', padx=(10,0), pady=10)\n",
    "        for name, _ in self.entries:\n",
    "            lb.insert('end', name)\n",
    "\n",
    "        btn_frame = ttk.Frame(dlg)\n",
    "        btn_frame.pack(side='left', fill='y', padx=10, pady=10)\n",
    "\n",
    "        def move(up):\n",
    "            idx = lb.curselection()\n",
    "            if not idx:\n",
    "                return\n",
    "            i = idx[0]\n",
    "            j = i-1 if up else i+1\n",
    "            if j<0 or j>=lb.size():\n",
    "                return\n",
    "            # swap in Listbox\n",
    "            name_i = lb.get(i)\n",
    "            name_j = lb.get(j)\n",
    "            lb.delete(i); lb.insert(i, name_j)\n",
    "            lb.delete(j); lb.insert(j, name_i)\n",
    "            lb.selection_clear(0,'end'); lb.selection_set(j)\n",
    "\n",
    "        ttk.Button(btn_frame, text=\"↑ Move Up\",   command=lambda: move(True)).pack(fill='x', pady=5)\n",
    "        ttk.Button(btn_frame, text=\"↓ Move Down\", command=lambda: move(False)).pack(fill='x', pady=5)\n",
    "        ttk.Separator(btn_frame, orient='horizontal').pack(fill='x', pady=5)\n",
    "        def apply_and_close():\n",
    "            # reorder self.entries to match Listbox\n",
    "            new_order = [lb.get(i) for i in range(lb.size())]\n",
    "            name_to_entry = {name: arr for name, arr in self.entries}\n",
    "            self.entries = [(n, name_to_entry[n]) for n in new_order]\n",
    "            self._rebuild_images_and_steps()\n",
    "            self.index = 0\n",
    "            self.show_current_image()\n",
    "            dlg.destroy()\n",
    "\n",
    "        ttk.Button(btn_frame, text=\"Apply\", command=apply_and_close).pack(fill='x', pady=(20,5))\n",
    "        ttk.Button(btn_frame, text=\"Cancel\", command=dlg.destroy).pack(fill='x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae2cec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpticalFlowPage(ttk.Frame):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "\n",
    "        # Available algorithms\n",
    "        self.algorithms = ['Farneback', 'Lucas-Kanade', 'Speckle Tracking', 'TVL1']\n",
    "        try:\n",
    "            self.tvl1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "        except Exception:\n",
    "            self.algorithms.remove('TVL1')\n",
    "            self.tvl1 = None\n",
    "\n",
    "        # Controls\n",
    "        ctrl = ttk.Frame(self)\n",
    "        ctrl.pack(fill='x', pady=10)\n",
    "        ttk.Button(ctrl, text=\"Select Folder\", command=self.load_images).pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Previous Image\", command=self.prev_image).pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Next Image\", command=self.next_image).pack(side='left', padx=5)\n",
    "\n",
    "        ttk.Label(ctrl, text=\"Algorithm:\").pack(side='left', padx=(20,5))\n",
    "        self.selected_alg = tk.StringVar(value=self.algorithms[0])\n",
    "        alg_combo = ttk.Combobox(ctrl, textvariable=self.selected_alg,\n",
    "                                 values=self.algorithms, state='readonly', width=15)\n",
    "        alg_combo.pack(side='left', padx=5)\n",
    "        alg_combo.bind('<<ComboboxSelected>>', lambda e: self.show_flow())\n",
    "\n",
    "        ttk.Label(ctrl, text=\"Grid Step:\").pack(side='left', padx=(20,5))\n",
    "        self.grid_step = tk.IntVar(value=20)\n",
    "        step_slider = ttk.Scale(ctrl, from_=1, to=20, variable=self.grid_step,\n",
    "                                command=lambda e: self.show_flow())\n",
    "        step_slider.pack(side='left', padx=5)\n",
    "        self.step_label = ttk.Label(ctrl, text=str(self.grid_step.get()))\n",
    "        self.step_label.pack(side='left')\n",
    "        self.grid_step.trace_add(\"write\", lambda *args: self.step_label.config(text=str(self.grid_step.get())))\n",
    "\n",
    "        self.show_net_var  = tk.BooleanVar(value=True)\n",
    "        self.show_inc_var  = tk.BooleanVar(value=True)\n",
    "        self.color_net_var = tk.BooleanVar(value=False)\n",
    "        ttk.Checkbutton(ctrl, text=\"Show Net Vector\",         variable=self.show_net_var,  command=self.show_flow).pack(side='left', padx=(20,5))\n",
    "        ttk.Checkbutton(ctrl, text=\"Show Incremental Vector\", variable=self.show_inc_var,  command=self.show_flow).pack(side='left', padx=5)\n",
    "        ttk.Checkbutton(ctrl, text=\"Color Net by Mag\",        variable=self.color_net_var, command=self.show_flow).pack(side='left', padx=5)\n",
    "\n",
    "        # Canvas for visualization\n",
    "        self.canvas = tk.Canvas(self, bg='#f0f0f0')\n",
    "        self.canvas.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "\n",
    "        # State\n",
    "        self.images = []\n",
    "        self.index  = 0\n",
    "        self.tk_imgs = []\n",
    "\n",
    "    def load_images(self):\n",
    "        folder = filedialog.askdirectory()\n",
    "        if not folder:\n",
    "            return\n",
    "\n",
    "        # 1) List all .png files in that folder\n",
    "        png_files = [f for f in os.listdir(folder) if f.lower().endswith('.png')]\n",
    "\n",
    "        # 2) Sort them by the integer part of the filename (e.g. \"0.png\"→0, \"10.png\"→10)\n",
    "        def numeric_key(fn):\n",
    "            name = os.path.splitext(fn)[0]\n",
    "            try:\n",
    "                return int(name)\n",
    "            except ValueError:\n",
    "                return fn  # non‐numeric names will sort lexicographically\n",
    "\n",
    "        png_files.sort(key=numeric_key)\n",
    "\n",
    "        # 3) Build full paths and load in that order\n",
    "        self.image_paths = [os.path.join(folder, f) for f in png_files]\n",
    "        self.images = [cv2.imread(p, cv2.IMREAD_GRAYSCALE) for p in self.image_paths]\n",
    "\n",
    "        # 4) Reset index and redraw\n",
    "        self.index = 0\n",
    "        self.show_flow()\n",
    "\n",
    "    def preprocess_variants(self, img):\n",
    "        variants = {\n",
    "            \"Raw\":      img.copy(),\n",
    "            \"Denoised\": cv2.medianBlur(img, 3)\n",
    "        }\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        variants[\"Enhanced\"] = clahe.apply(variants[\"Denoised\"])\n",
    "        return variants\n",
    "\n",
    "    def compute_flow(self, img1, img2, method):\n",
    "        if method == 'Farneback':\n",
    "            return cv2.calcOpticalFlowFarneback(\n",
    "                img1, img2, None,\n",
    "                pyr_scale=0.5, levels=3,\n",
    "                winsize=15, iterations=3,\n",
    "                poly_n=5, poly_sigma=1.2, flags=0\n",
    "            )\n",
    "        if method == 'TVL1' and self.tvl1:\n",
    "            return self.tvl1.calc(img1, img2, None)\n",
    "        if method == 'Lucas-Kanade':\n",
    "            p0 = cv2.goodFeaturesToTrack(img1, maxCorners=200,\n",
    "                                         qualityLevel=0.01, minDistance=7, blockSize=7)\n",
    "            if p0 is None:\n",
    "                return None\n",
    "            p1, st, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                img1, img2, p0, None,\n",
    "                winSize=(15,15), maxLevel=2\n",
    "            )\n",
    "            pts0 = p0[st.flatten()==1].reshape(-1,2)\n",
    "            pts1 = p1[st.flatten()==1].reshape(-1,2)\n",
    "            return (pts0, pts1)\n",
    "        if method == 'Speckle Tracking':\n",
    "            h, w = img1.shape\n",
    "            pts = np.array([[x, y]\n",
    "                            for y in range(0, h, self.grid_step.get())\n",
    "                            for x in range(0, w, self.grid_step.get())])\n",
    "            pts1 = []\n",
    "            half_t = 5\n",
    "            tpl_h, tpl_w = 2*half_t+1, 2*half_t+1\n",
    "            s = self.grid_step.get()\n",
    "            for x0,y0 in pts:\n",
    "                tpl = img1[max(y0-half_t,0):y0+half_t+1,\n",
    "                           max(x0-half_t,0):x0+half_t+1]\n",
    "                win = img2[max(y0-s,0):y0+s+1,\n",
    "                           max(x0-s,0):x0+s+1]\n",
    "                if win.shape[0]<tpl_h or win.shape[1]<tpl_w:\n",
    "                    pts1.append((x0,y0))\n",
    "                    continue\n",
    "                res = cv2.matchTemplate(win, tpl, cv2.TM_CCOEFF_NORMED)\n",
    "                _,_,_,max_loc = cv2.minMaxLoc(res)\n",
    "                dx = max_loc[0] - (win.shape[1]//2 - half_t)\n",
    "                dy = max_loc[1] - (win.shape[0]//2 - half_t)\n",
    "                pts1.append((x0+dx, y0+dy))\n",
    "            return (pts, np.array(pts1))\n",
    "        return None\n",
    "\n",
    "    def draw_arrows(self, vis, flow, method, color):\n",
    "        step = self.grid_step.get()\n",
    "        if method in ['Farneback','TVL1']:\n",
    "            h,w = vis.shape[:2]\n",
    "            y,x = np.mgrid[step//2:h:step, step//2:w:step].astype(int)\n",
    "            fx,fy = flow[y,x].T\n",
    "            for x0,y0,dx,dy in zip(x.flatten(),y.flatten(),fx.flatten(),fy.flatten()):\n",
    "                cv2.arrowedLine(vis, (x0,y0), (int(x0+dx),int(y0+dy)),\n",
    "                                color=color, thickness=1)\n",
    "        else:\n",
    "            pts0,pts1 = flow\n",
    "            for (x0,y0),(x1,y1) in zip(pts0,pts1):\n",
    "                cv2.arrowedLine(vis, (int(x0),int(y0)), (int(x1),int(y1)),\n",
    "                                color=color, thickness=1)\n",
    "\n",
    "    def _draw_arrows_from_pts(self, vis, pts0, disp, color_or_lut):\n",
    "        if isinstance(color_or_lut, tuple):\n",
    "            for (x0,y0),(dx,dy) in zip(pts0, disp):\n",
    "                cv2.arrowedLine(vis, (int(x0),int(y0)), (int(x0+dx),int(y0+dy)),\n",
    "                                color_or_lut, thickness=1)\n",
    "        else:\n",
    "            lut = color_or_lut[:,0]\n",
    "            mags = np.hypot(disp[:,0], disp[:,1])\n",
    "            maxm = mags.max() or 1.0\n",
    "            for (x0,y0),(dx,dy),m in zip(pts0, disp, mags):\n",
    "                idx = int(255 * min(m/maxm,1.0))\n",
    "                b,g,r = lut[idx]\n",
    "                cv2.arrowedLine(vis, (int(x0),int(y0)), (int(x0+dx),int(y0+dy)),\n",
    "                                (int(b),int(g),int(r)), thickness=1)\n",
    "\n",
    "    def show_flow(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.tk_imgs.clear()\n",
    "        if not self.images:\n",
    "            return\n",
    "\n",
    "        alg      = self.selected_alg.get()\n",
    "        show_inc = self.show_inc_var.get()\n",
    "        show_net = self.show_net_var.get()\n",
    "        color_net= self.color_net_var.get()\n",
    "        step     = self.grid_step.get()\n",
    "\n",
    "        curr = self.images[self.index]\n",
    "        prev = self.images[self.index-1] if self.index>0 else None\n",
    "        ref  = self.images[0]           if self.index>0 else None\n",
    "\n",
    "        curr_vars = self.preprocess_variants(curr)\n",
    "        prev_vars = self.preprocess_variants(prev) if prev is not None else {}\n",
    "        ref_vars  = self.preprocess_variants(ref)  if ref  is not None else {}\n",
    "\n",
    "        self.canvas.update_idletasks()\n",
    "        W   = self.canvas.winfo_width(); pad = 20\n",
    "        tw  = (W - pad*4)//3\n",
    "\n",
    "        for idx, var in enumerate([\"Raw\",\"Denoised\",\"Enhanced\"]):\n",
    "            vis = cv2.cvtColor(curr_vars[var], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            if self.index > 0:\n",
    "                # incremental\n",
    "                if show_inc:\n",
    "                    flow_prev = self.compute_flow(prev_vars[var], curr_vars[var], alg)\n",
    "                    if flow_prev is not None:\n",
    "                        self.draw_arrows(vis, flow_prev, alg, (0,255,0))\n",
    "\n",
    "                # net\n",
    "                if show_net:\n",
    "                    flow_net = self.compute_flow(ref_vars[var], curr_vars[var], alg)\n",
    "                    if flow_net is not None:\n",
    "                        # extract pts0, disp\n",
    "                        if isinstance(flow_net, tuple):\n",
    "                            p0, p1 = flow_net\n",
    "                            pts0, disp = p0.astype(int), p1 - p0\n",
    "                        else:\n",
    "                            h,w = flow_net.shape[:2]\n",
    "                            y,x = np.mgrid[step//2:h:step, step//2:w:step].astype(int)\n",
    "                            pts0 = np.stack([x.flatten(), y.flatten()], axis=-1)\n",
    "                            fx,fy = flow_net[...,0], flow_net[...,1]\n",
    "                            disp = np.stack([fx[y,x], fy[y,x]], axis=-1).reshape(-1,2)\n",
    "\n",
    "                        if color_net:\n",
    "                            jet_lut = cv2.applyColorMap(\n",
    "                                np.arange(256, dtype=np.uint8),\n",
    "                                cv2.COLORMAP_JET\n",
    "                            )\n",
    "                            self._draw_arrows_from_pts(vis, pts0, disp, jet_lut)\n",
    "                        else:\n",
    "                            self._draw_arrows_from_pts(vis, pts0, disp, (0,0,255))\n",
    "\n",
    "            # thumbnail & display\n",
    "            h2,w2 = vis.shape[:2]; th = int(tw*h2/w2)\n",
    "            thumb = cv2.resize(vis, (tw,th), interpolation=cv2.INTER_AREA)\n",
    "            img_tk = ImageTk.PhotoImage(Image.fromarray(\n",
    "                        cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB)))\n",
    "            self.tk_imgs.append(img_tk)\n",
    "            x = pad + idx*(tw+pad); y = pad\n",
    "            self.canvas.create_image(x, y, anchor='nw', image=img_tk)\n",
    "            self.canvas.create_text(x+tw//2, y+th+10,\n",
    "                                    text=var, font=(\"Helvetica\",8,\"bold\"))\n",
    "\n",
    "        self.master.master.title(f\"{alg} — Img0→Img{self.index}/{len(self.images)-1}\")\n",
    "\n",
    "    def next_image(self):\n",
    "        if self.index < len(self.images)-1:\n",
    "            self.index += 1\n",
    "            self.show_flow()\n",
    "\n",
    "    def prev_image(self):\n",
    "        if self.index > 0:\n",
    "            self.index -= 1\n",
    "            self.show_flow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5dccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureRegistrationPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "\n",
    "        # --- Controls bar ---\n",
    "        ctrl = ttk.Frame(self)\n",
    "        ctrl.pack(fill='x', pady=10)\n",
    "\n",
    "        ttk.Button(ctrl, text=\"Select Folder\", command=self.load_images).pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Previous\",      command=self.prev_image).pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Next\",          command=self.next_image).pack(side='left', padx=5)\n",
    "\n",
    "        # Relative threshold slider (background minus pixel)\n",
    "        ttk.Label(ctrl, text=\"Rel Thresh:\").pack(side='left', padx=(20,5))\n",
    "        self.rel_thresh = tk.IntVar(value=15)\n",
    "        rel_sld = ttk.Scale(ctrl, from_=0, to=100, variable=self.rel_thresh,\n",
    "                            command=lambda e: self.show_registration())\n",
    "        rel_sld.pack(side='left')\n",
    "        self.rel_lbl = ttk.Label(ctrl, text=str(self.rel_thresh.get()))\n",
    "        self.rel_lbl.pack(side='left', padx=(5,10))\n",
    "        self.rel_thresh.trace_add(\"write\",\n",
    "            lambda *a: self.rel_lbl.config(text=str(self.rel_thresh.get()))\n",
    "        )\n",
    "\n",
    "        # Min contour area slider\n",
    "        ttk.Label(ctrl, text=\"Min Area:\").pack(side='left', padx=(10,5))\n",
    "        self.min_area = tk.IntVar(value=50)\n",
    "        area_sld = ttk.Scale(ctrl, from_=10, to=2000, variable=self.min_area,\n",
    "                             command=lambda e: self.show_registration())\n",
    "        area_sld.pack(side='left', padx=(0,5))\n",
    "        self.area_lbl = ttk.Label(ctrl, text=str(self.min_area.get()))\n",
    "        self.area_lbl.pack(side='left')\n",
    "        self.min_area.trace_add(\"write\",\n",
    "            lambda *a: self.area_lbl.config(text=str(self.min_area.get()))\n",
    "        )\n",
    "\n",
    "        # --- Canvas ---\n",
    "        self.canvas = tk.Canvas(self, bg='#f0f0f0')\n",
    "        self.canvas.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "\n",
    "        # --- State ---\n",
    "        self.images = []    # grayscale frames\n",
    "        self.index  = 0\n",
    "        self.tk_imgs = []   # PhotoImage refs\n",
    "\n",
    "    def load_images(self):\n",
    "        folder = filedialog.askdirectory()\n",
    "        if not folder:\n",
    "            return\n",
    "\n",
    "        fnames = [f for f in os.listdir(folder) if f.lower().endswith('.png')]\n",
    "        fnames.sort(key=lambda fn: int(os.path.splitext(fn)[0]) if fn[:-4].isdigit() else fn)\n",
    "        self.images = [\n",
    "            cv2.imread(os.path.join(folder, fn), cv2.IMREAD_GRAYSCALE)\n",
    "            for fn in fnames\n",
    "        ]\n",
    "        if not self.images:\n",
    "            return\n",
    "\n",
    "        self.index = 0\n",
    "        self.show_registration()\n",
    "\n",
    "    def _segment_local_dark_spots(self, img):\n",
    "        \"\"\"\n",
    "        Finds spots darker than their local background.\n",
    "        Returns filtered contours.\n",
    "        \"\"\"\n",
    "        # 1) compute local background by Gaussian blur\n",
    "        #    kernel size = roughly 1/10th of min dimension, odd\n",
    "        k = max(5, (min(img.shape)//10)//2*2+1)\n",
    "        bg = cv2.GaussianBlur(img, (k,k), 0)\n",
    "\n",
    "        # 2) difference image: bg - img\n",
    "        diff = cv2.subtract(bg, img)\n",
    "\n",
    "        # 3) threshold difference\n",
    "        thresh = self.rel_thresh.get()\n",
    "        _, mask = cv2.threshold(diff, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # 4) clean mask\n",
    "        kern = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kern, iterations=1)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kern, iterations=2)\n",
    "\n",
    "        # 5) find contours\n",
    "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # 6) filter by area\n",
    "        h, w = img.shape\n",
    "        min_a = self.min_area.get()\n",
    "        max_a = 0.8 * h * w\n",
    "        good = [c for c in cnts\n",
    "                if min_a <= cv2.contourArea(c) <= max_a]\n",
    "        return good\n",
    "\n",
    "    def show_registration(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.tk_imgs.clear()\n",
    "        if not self.images:\n",
    "            return\n",
    "\n",
    "        img = self.images[self.index]\n",
    "\n",
    "        # prepare three variants\n",
    "        denoised = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced = clahe.apply(denoised)\n",
    "        variants = [('Raw', img), ('Denoised', denoised), ('Enhanced', enhanced)]\n",
    "\n",
    "        # layout thumbnails\n",
    "        self.canvas.update_idletasks()\n",
    "        W = self.canvas.winfo_width()\n",
    "        pad = 20\n",
    "        thumb_w = (W - pad*4) // 3\n",
    "\n",
    "        for i, (name, vimg) in enumerate(variants):\n",
    "            vis = cv2.cvtColor(vimg, cv2.COLOR_GRAY2BGR)\n",
    "            # detect local dark spots\n",
    "            cnts = self._segment_local_dark_spots(vimg)\n",
    "            # draw outlines in green\n",
    "            cv2.drawContours(vis, cnts, -1, (0,255,0), 1)\n",
    "\n",
    "            # resize to thumbnail\n",
    "            h, w = vis.shape[:2]\n",
    "            thumb_h = int(thumb_w * h / w)\n",
    "            thumb = cv2.resize(vis, (thumb_w, thumb_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            imgtk = ImageTk.PhotoImage(Image.fromarray(thumb))\n",
    "            self.tk_imgs.append(imgtk)\n",
    "\n",
    "            x = pad + i*(thumb_w + pad)\n",
    "            y = pad\n",
    "            self.canvas.create_image(x, y, anchor='nw', image=imgtk)\n",
    "            self.canvas.create_text(\n",
    "                x + thumb_w//2, y + thumb_h + 12,\n",
    "                text=name, font=(\"Helvetica\", 9, \"bold\"), fill=\"#333\"\n",
    "            )\n",
    "\n",
    "        total = len(self.images)\n",
    "        self.master.master.title(\n",
    "            f\"Local Dark Spots — Img{self.index}/{total-1}  \"\n",
    "            f\"(Δ>{self.rel_thresh.get()}, Area>{self.min_area.get()})\"\n",
    "        )\n",
    "\n",
    "    def next_image(self):\n",
    "        if self.index < len(self.images)-1:\n",
    "            self.index += 1\n",
    "            self.show_registration()\n",
    "\n",
    "    def prev_image(self):\n",
    "        if self.index > 0:\n",
    "            self.index -= 1\n",
    "            self.show_registration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b819fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearningRegistrationPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Deep Learning Registration\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4e5ce13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModelPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Hybrid Model (Feature + Flow + Deep Learning)\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2a76ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkingPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Benchmarking Framework\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "333502e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Main Application ===\n",
    "class MainApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"OCT Deformation Tracking Suite\")\n",
    "        self.geometry(\"1200x800\")\n",
    "        style = ttk.Style(self)\n",
    "        style.theme_use('clam')\n",
    "        style.configure('TNotebook.Tab', padding=(10, 10))\n",
    "\n",
    "        notebook = ttk.Notebook(self)\n",
    "        notebook.pack(fill='both', expand=True)\n",
    "\n",
    "        # Add pages to notebook\n",
    "        for PageClass, title in [\n",
    "            (HomePage, \"Home\"),\n",
    "            (PreprocessingPage, \"Preprocessing\"),\n",
    "            (OpticalFlowPage, \"Optical Flow\"),\n",
    "            (FeatureRegistrationPage, \"Feature Reg.\"),\n",
    "            (DeepLearningRegistrationPage, \"Deep Learning\"),\n",
    "            (HybridModelPage, \"Hybrid Model\"),\n",
    "            (BenchmarkingPage, \"Benchmarking\"),\n",
    "        ]:\n",
    "            page = PageClass(notebook)\n",
    "            notebook.add(page, text=title)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MainApp().mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
