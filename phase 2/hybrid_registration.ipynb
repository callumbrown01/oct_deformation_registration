{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "de032f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ce850c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This section is designed to optimise image pre-processing \n",
    "Aims:\n",
    "- manage sequential images and folder structure such that sequence is easily retained\n",
    "- perform visual/mathematical filtering to refine image contrast and enable the subsequent algorithm\n",
    "- denoising the image (speckle decorrelation?)\n",
    "- contrast enhancement\n",
    "- motion artifact correction?\n",
    "'''\n",
    "# input variable is a folder containing png images in chronological order for now.\n",
    "def preprocess_image_sequence(image_sequence):\n",
    "\n",
    "    # create a dir for sequential preprocessed images\n",
    "    if not os.path.exists(\"denoised_sequence\"):\n",
    "        os.makedirs(\"denoised_sequence\")\n",
    "    if not os.path.exists(\"contrasted_sequence\"):\n",
    "        os.makedirs(\"contrasted_sequence\")\n",
    "    if not os.path.exists(\"preprocessed_sequence\"):\n",
    "        os.makedirs(\"preprocessed_sequence\")\n",
    "\n",
    "    # sort image paths from input folder\n",
    "    image_paths = sorted(glob(os.path.join(image_sequence, \"*.png\")))\n",
    "\n",
    "    # read first image as the reference image\n",
    "    reference_image = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # read in current image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # denoise image via median filtering \n",
    "        denoised_image = cv2.medianBlur(image, 3)\n",
    "        output_path = os.path.join(\"denoised_sequence\", f\"{idx:03d}.png\")\n",
    "        cv2.imwrite(output_path, denoised_image)\n",
    "\n",
    "        # contrast enhancement via adaptive histogram equalisation\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced_image = clahe.apply(denoised_image)\n",
    "        output_path = os.path.join(\"contrasted_sequence\", f\"{idx:03d}.png\")\n",
    "        cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "        # motion artifact correction or rigid alignment of current image to the reference image\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        _, warp_matrix = cv2.findTransformECC(reference_image, enhanced_image, warp_matrix, cv2.MOTION_EUCLIDEAN)\n",
    "\n",
    "        corrected_image = cv2.warpAffine(enhanced_image, warp_matrix, (enhanced_image.shape[1], enhanced_image.shape[0]),\n",
    "                                         flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        output_path = os.path.join(\"preprocessed_sequence\", f\"{idx:03d}.png\")\n",
    "        cv2.imwrite(output_path, corrected_image)\n",
    "\n",
    "    # Visualize the steps\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "    images = [image, denoised_image, enhanced_image, corrected_image]\n",
    "    titles = ['Original', 'Denoised', 'Contrast Enhanced', 'Motion Corrected']\n",
    "\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"preprocessing_pipeline\")\n",
    "\n",
    "# a simplified single image process for utilisation by the tkinter \n",
    "def preprocess_single_image(img, reference_img=None):\n",
    "    steps = {}\n",
    "\n",
    "    # Step 1: Original\n",
    "    steps['Original'] = img.copy()\n",
    "\n",
    "    # Step 2: Denoising\n",
    "    denoised = cv2.medianBlur(img, 3)\n",
    "    steps['Denoised'] = denoised\n",
    "\n",
    "    # Step 3: Contrast Enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    steps['Contrast Enhanced'] = enhanced\n",
    "\n",
    "    # Step 4: Motion Artifact Correction\n",
    "    if reference_img is not None:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        try:\n",
    "            _, warp_matrix = cv2.findTransformECC(reference_img, enhanced, warp_matrix, cv2.MOTION_EUCLIDEAN)\n",
    "            corrected = cv2.warpAffine(enhanced, warp_matrix, (enhanced.shape[1], enhanced.shape[0]),\n",
    "                                       flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        except cv2.error:\n",
    "            corrected = enhanced.copy()  # fallback if ECC fails\n",
    "    else:\n",
    "        corrected = enhanced.copy()\n",
    "\n",
    "    steps['Motion Corrected'] = corrected\n",
    "\n",
    "    return steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "d3745bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The purpose of this section is to test combinations of several tracking algorithms into a single, hybrid methodology\n",
    "Aims:\n",
    "- building a combined hybrid methodology which factors the strengths of each algorithm\n",
    "- tweaking the influence or 'strength' of each algorithm based on overall model performance\n",
    "- perhaps model efficiency optimisation\n",
    "'''\n",
    "\n",
    "# optical tracking implementation\n",
    "'''\n",
    "Meant to target larger homogeneous regions of the tissue (areas of similar contrast)\n",
    "'''\n",
    "def optical_tracking():\n",
    "    return 0\n",
    "\n",
    "# feature based alignment implementation\n",
    "'''\n",
    "Meant to target tissue landmarks and structures\n",
    "need to test some segmentation algorithms and maybe combine to form an OCT optimal strategy\n",
    "'''\n",
    "def feature_alignment():\n",
    "    return 0\n",
    "\n",
    "# deep learning fine-tuning tracking implementation\n",
    "'''\n",
    "Uses a library of labelled imagery to make tracking adjustments\n",
    "not sure yet on method of implementation, probably looking at CNN\n",
    "'''\n",
    "def CNN():\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "fdb5103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Base Page Class ===\n",
    "class Page(tk.Frame):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "\n",
    "# === Individual Pages ===\n",
    "class HomePage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        label = ttk.Label(self, text=\"Welcome to the OCT Deformation Tracking Suite\", font=(\"Helvetica\", 18))\n",
    "        label.pack(pady=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c4f41895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        # Controls\n",
    "        controls = ttk.Frame(self)\n",
    "        controls.pack(fill='x', pady=10)\n",
    "        ttk.Button(controls, text=\"Select Folder\", command=self.load_images).pack(side='left', padx=5)\n",
    "        ttk.Button(controls, text=\"Previous\", command=self.prev_image).pack(side='left', padx=5)\n",
    "        ttk.Button(controls, text=\"Next\", command=self.next_image).pack(side='left', padx=5)\n",
    "        # Canvas\n",
    "        self.canvas = tk.Canvas(self, bg='#f0f0f0')\n",
    "        self.canvas.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "        # State\n",
    "        self.images = []\n",
    "        self.reference_img = None\n",
    "        self.index = 0\n",
    "        self.preprocessed_steps = []\n",
    "        self.tk_imgs = {}\n",
    "\n",
    "    def preprocess_single_image(self, img, reference_img=None):\n",
    "        steps = {'Original': img.copy()}\n",
    "        denoised = cv2.medianBlur(img, 3); steps['Denoised'] = denoised\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced = clahe.apply(denoised); steps['Contrast Enhanced'] = enhanced\n",
    "        if reference_img is not None:\n",
    "            warp_matrix = np.eye(2,3, dtype=np.float32)\n",
    "            try:\n",
    "                _, warp_matrix = cv2.findTransformECC(reference_img, enhanced, warp_matrix, cv2.MOTION_EUCLIDEAN)\n",
    "                corrected = cv2.warpAffine(enhanced, warp_matrix, (enhanced.shape[1], enhanced.shape[0]),\n",
    "                                           flags=cv2.INTER_LINEAR+cv2.WARP_INVERSE_MAP)\n",
    "            except cv2.error:\n",
    "                corrected = enhanced.copy()\n",
    "        else:\n",
    "            corrected = enhanced.copy()\n",
    "        steps['Motion Corrected'] = corrected\n",
    "        return steps\n",
    "\n",
    "    def load_images(self):\n",
    "        folder = filedialog.askdirectory()\n",
    "        if not folder:\n",
    "            return\n",
    "        paths = sorted(glob(folder + \"/*.png\"))\n",
    "        self.images = [cv2.imread(p, cv2.IMREAD_GRAYSCALE) for p in paths]\n",
    "        self.reference_img = self.images[0] if self.images else None\n",
    "        self.index = 0\n",
    "        self.preprocessed_steps = [self.preprocess_single_image(img, self.reference_img) for img in self.images]\n",
    "        self.show_current_image()\n",
    "\n",
    "    def show_current_image(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        if not self.preprocessed_steps:\n",
    "            return\n",
    "        steps = self.preprocessed_steps[self.index]\n",
    "        titles = list(steps.keys())\n",
    "        for i, title in enumerate(titles):\n",
    "            img = steps[title]\n",
    "            img = Image.fromarray(img).resize((220, 220))\n",
    "            tk_img = ImageTk.PhotoImage(img)\n",
    "            self.tk_imgs[i] = tk_img\n",
    "            x = 10 + i * 240\n",
    "            self.canvas.create_image(x, 10, anchor='nw', image=tk_img)\n",
    "            self.canvas.create_text(x + 110, 240, text=title, font=(\"Helvetica\", 12))\n",
    "        self.canvas.update()\n",
    "\n",
    "    def next_image(self):\n",
    "        if self.index < len(self.images) - 1:\n",
    "            self.index += 1\n",
    "            self.show_current_image()\n",
    "    def prev_image(self):\n",
    "        if self.index > 0:\n",
    "            self.index -= 1\n",
    "            self.show_current_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "ae2cec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class OpticalFlowPage(ttk.Frame):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "\n",
    "        # Available algorithms\n",
    "        self.algorithms = ['Farneback', 'Lucas-Kanade', 'Speckle Tracking', 'TVL1']\n",
    "        try:\n",
    "            self.tvl1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "        except Exception:\n",
    "            self.algorithms.remove('TVL1')\n",
    "            self.tvl1 = None\n",
    "\n",
    "        # Controls\n",
    "        ctrl = ttk.Frame(self)\n",
    "        ctrl.pack(fill='x', pady=10)\n",
    "\n",
    "        # State\n",
    "        self.images = []\n",
    "        self.index  = 0\n",
    "        self.tk_imgs = []\n",
    "\n",
    "        ttk.Button(ctrl, text=\"Select Folder\", command=self.load_images).pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Previous Image\", command=self.prev_image).pack(side='left', padx=5)\n",
    "        ttk.Button(ctrl, text=\"Next Image\", command=self.next_image).pack(side='left', padx=5)\n",
    "\n",
    "        ttk.Label(ctrl, text=\"Algorithm:\").pack(side='left', padx=(20,5))\n",
    "        self.selected_alg = tk.StringVar(value=self.algorithms[0])\n",
    "        alg_combo = ttk.Combobox(ctrl, textvariable=self.selected_alg,\n",
    "                                 values=self.algorithms, state='readonly', width=15)\n",
    "        alg_combo.pack(side='left', padx=5)\n",
    "        alg_combo.bind('<<ComboboxSelected>>', lambda e: self.show_flow())\n",
    "\n",
    "        ttk.Label(ctrl, text=\"Grid Step:\").pack(side='left', padx=(20,5))\n",
    "        self.grid_step = tk.IntVar(value=20)\n",
    "        step_slider = ttk.Scale(ctrl, from_=5, to=50, variable=self.grid_step,\n",
    "                                command=lambda e: self.show_flow())\n",
    "        step_slider.pack(side='left', padx=5)\n",
    "        self.step_label = ttk.Label(ctrl, text=str(self.grid_step.get()))\n",
    "        self.step_label.pack(side='left')\n",
    "        self.grid_step.trace_add(\"write\", lambda *args: self.step_label.config(text=str(self.grid_step.get())))\n",
    "\n",
    "        self.show_net_var  = tk.BooleanVar(value=True)\n",
    "        self.show_inc_var  = tk.BooleanVar(value=True)\n",
    "        self.color_net_var = tk.BooleanVar(value=False)\n",
    "        ttk.Checkbutton(ctrl, text=\"Show Net Vector\",         variable=self.show_net_var,  command=self.show_flow).pack(side='left', padx=(20,5))\n",
    "        ttk.Checkbutton(ctrl, text=\"Show Incremental Vector\", variable=self.show_inc_var,  command=self.show_flow).pack(side='left', padx=5)\n",
    "        ttk.Checkbutton(ctrl, text=\"Color Net by Mag\",        variable=self.color_net_var, command=self.show_flow).pack(side='left', padx=5)\n",
    "\n",
    "        # Canvas for visualization\n",
    "        self.canvas = tk.Canvas(self, bg='#f0f0f0')\n",
    "        self.canvas.pack(fill='both', expand=True, padx=10, pady=10)\n",
    "\n",
    "        \n",
    "\n",
    "    def load_images(self):\n",
    "        folder = filedialog.askdirectory()\n",
    "        if not folder:\n",
    "            return\n",
    "        import os, glob\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(folder, \"*.png\")))\n",
    "        self.images      = [cv2.imread(p, cv2.IMREAD_GRAYSCALE) for p in self.image_paths]\n",
    "        self.index       = 0\n",
    "        self.show_flow()\n",
    "\n",
    "    def preprocess_variants(self, img):\n",
    "        variants = {\n",
    "            \"Raw\":      img.copy(),\n",
    "            \"Denoised\": cv2.medianBlur(img, 3)\n",
    "        }\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        variants[\"Enhanced\"] = clahe.apply(variants[\"Denoised\"])\n",
    "        return variants\n",
    "\n",
    "    def compute_flow(self, img1, img2, method):\n",
    "        if method == 'Farneback':\n",
    "            return cv2.calcOpticalFlowFarneback(\n",
    "                img1, img2, None,\n",
    "                pyr_scale=0.5, levels=3,\n",
    "                winsize=15, iterations=3,\n",
    "                poly_n=5, poly_sigma=1.2,\n",
    "                flags=0\n",
    "            )\n",
    "        if method == 'TVL1' and self.tvl1:\n",
    "            return self.tvl1.calc(img1, img2, None)\n",
    "        if method == 'Lucas-Kanade':\n",
    "            p0 = cv2.goodFeaturesToTrack(\n",
    "                img1, maxCorners=200,\n",
    "                qualityLevel=0.01, minDistance=7, blockSize=7\n",
    "            )\n",
    "            if p0 is None:\n",
    "                return None\n",
    "            p1, st, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                img1, img2, p0, None,\n",
    "                winSize=(15,15), maxLevel=2\n",
    "            )\n",
    "            pts0 = p0[st.flatten()==1].reshape(-1,2)\n",
    "            pts1 = p1[st.flatten()==1].reshape(-1,2)\n",
    "            return (pts0, pts1)\n",
    "        if method == 'Speckle Tracking':\n",
    "            h, w = img1.shape\n",
    "            pts = np.array([\n",
    "                [x, y]\n",
    "                for y in range(0, h, self.grid_step.get())\n",
    "                for x in range(0, w, self.grid_step.get())\n",
    "            ])\n",
    "            pts1 = []\n",
    "            half_t = 5\n",
    "            tpl_h, tpl_w = 2*half_t+1, 2*half_t+1\n",
    "            s = self.grid_step.get()\n",
    "            for x0,y0 in pts:\n",
    "                tpl = img1[\n",
    "                    max(y0-half_t,0):y0+half_t+1,\n",
    "                    max(x0-half_t,0):x0+half_t+1\n",
    "                ]\n",
    "                win = img2[\n",
    "                    max(y0-s,0):y0+s+1,\n",
    "                    max(x0-s,0):x0+s+1\n",
    "                ]\n",
    "                if win.shape[0]<tpl_h or win.shape[1]<tpl_w:\n",
    "                    pts1.append((x0,y0))\n",
    "                    continue\n",
    "                res = cv2.matchTemplate(win, tpl, cv2.TM_CCOEFF_NORMED)\n",
    "                _,_,_,max_loc = cv2.minMaxLoc(res)\n",
    "                dx = max_loc[0] - (win.shape[1]//2 - half_t)\n",
    "                dy = max_loc[1] - (win.shape[0]//2 - half_t)\n",
    "                pts1.append((x0+dx, y0+dy))\n",
    "            return (pts, np.array(pts1))\n",
    "        return None\n",
    "\n",
    "    def draw_arrows(self, vis, flow, method, color):\n",
    "        step = self.grid_step.get()\n",
    "        if method in ['Farneback','TVL1']:\n",
    "            h,w = vis.shape[:2]\n",
    "            y,x = np.mgrid[step//2:h:step, step//2:w:step].astype(int)\n",
    "            fx,fy = flow[y,x].T\n",
    "            for x0,y0,dx,dy in zip(x.flatten(),y.flatten(),fx.flatten(),fy.flatten()):\n",
    "                cv2.arrowedLine(\n",
    "                    vis, (x0,y0), (int(x0+dx),int(y0+dy)),\n",
    "                    color=color, thickness=1\n",
    "                )\n",
    "        else:\n",
    "            pts0,pts1 = flow\n",
    "            for (x0,y0),(x1,y1) in zip(pts0,pts1):\n",
    "                cv2.arrowedLine(\n",
    "                    vis, (int(x0),int(y0)), (int(x1),int(y1)),\n",
    "                    color=color, thickness=1\n",
    "                )\n",
    "\n",
    "    def _draw_arrows_from_pts(self, vis, pts0, disp, color_or_lut):\n",
    "        \"\"\"\n",
    "        Draw arrows from pts0 with displacement disp.\n",
    "        color_or_lut: BGR tuple for uniform color or LUT (256×1×3) for JET mapping.\n",
    "        \"\"\"\n",
    "        if isinstance(color_or_lut, tuple):\n",
    "            for (x0,y0),(dx,dy) in zip(pts0, disp):\n",
    "                cv2.arrowedLine(vis,\n",
    "                                (int(x0),int(y0)),\n",
    "                                (int(x0+dx),int(y0+dy)),\n",
    "                                color_or_lut, thickness=1)\n",
    "        else:\n",
    "            lut = color_or_lut[:,0]  # shape (256,3)\n",
    "            mags = np.hypot(disp[:,0], disp[:,1])\n",
    "            maxm = mags.max() or 1.0\n",
    "            for (x0,y0),(dx,dy),m in zip(pts0, disp, mags):\n",
    "                idx = int(255 * min(m/maxm, 1.0))\n",
    "                b,g,r = lut[idx]\n",
    "                cv2.arrowedLine(vis,\n",
    "                                (int(x0),int(y0)),\n",
    "                                (int(x0+dx),int(y0+dy)),\n",
    "                                (int(b),int(g),int(r)), thickness=1)\n",
    "\n",
    "    def show_flow(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.tk_imgs.clear()\n",
    "        if not self.images:\n",
    "            return\n",
    "\n",
    "        alg       = self.selected_alg.get()\n",
    "        curr      = self.images[self.index]\n",
    "        prev      = self.images[self.index-1] if self.index>0 else curr\n",
    "        ref       = self.images[0]\n",
    "        show_net  = self.show_net_var.get()\n",
    "        show_inc  = self.show_inc_var.get()\n",
    "        color_net = self.color_net_var.get()\n",
    "\n",
    "        curr_vars = self.preprocess_variants(curr)\n",
    "        prev_vars = self.preprocess_variants(prev)\n",
    "        ref_vars  = self.preprocess_variants(ref)\n",
    "\n",
    "        # Precompute net flows & displacements\n",
    "        net_disps = {}\n",
    "        maxima    = []\n",
    "        for var in [\"Raw\",\"Denoised\",\"Enhanced\"]:\n",
    "            f = self.compute_flow(ref_vars[var], curr_vars[var], alg)\n",
    "            if f is None:\n",
    "                net_disps[var] = (np.zeros((0,2),int), np.zeros((0,2),float))\n",
    "                maxima.append(0.0)\n",
    "            elif isinstance(f, tuple):\n",
    "                p0,p1 = f\n",
    "                disp = p1 - p0\n",
    "                net_disps[var] = (p0.astype(int), disp)\n",
    "                maxima.append(np.linalg.norm(disp,axis=1).max() if len(disp)>0 else 0.0)\n",
    "            else:  # dense\n",
    "                step = self.grid_step.get()\n",
    "                h,w = f.shape[:2]\n",
    "                y,x = np.mgrid[step//2:h:step, step//2:w:step].astype(int)\n",
    "                pts0 = np.stack([x.flatten(), y.flatten()],axis=-1)\n",
    "                fx,fy = f[...,0], f[...,1]\n",
    "                disp = np.stack([fx[y,x], fy[y,x]],axis=-1).reshape(-1,2)\n",
    "                net_disps[var] = (pts0, disp)\n",
    "                maxima.append(np.hypot(disp[:,0],disp[:,1]).max() if disp.size else 0.0)\n",
    "\n",
    "        global_max = max(maxima) or 1.0\n",
    "        jet_lut    = cv2.applyColorMap(np.arange(256,dtype=np.uint8), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Canvas sizing\n",
    "        self.canvas.update_idletasks()\n",
    "        W   = self.canvas.winfo_width()\n",
    "        pad = 20\n",
    "        tw  = (W - pad*4)//3\n",
    "\n",
    "        for idx,var in enumerate([\"Raw\",\"Denoised\",\"Enhanced\"]):\n",
    "            vis = cv2.cvtColor(curr_vars[var], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            # Incremental (green)\n",
    "            if show_inc:\n",
    "                f_inc = self.compute_flow(prev_vars[var], curr_vars[var], alg)\n",
    "                if f_inc is not None:\n",
    "                    self.draw_arrows(vis, f_inc, alg, (0,255,0))\n",
    "\n",
    "            # Net\n",
    "            if show_net:\n",
    "                p0, disp = net_disps[var]\n",
    "                if p0.size:\n",
    "                    if color_net:\n",
    "                        self._draw_arrows_from_pts(vis, p0, disp, jet_lut)\n",
    "                    else:\n",
    "                        self._draw_arrows_from_pts(vis, p0, disp, (0,0,255))\n",
    "\n",
    "            # Thumbnail & display\n",
    "            h2,w2 = vis.shape[:2]\n",
    "            th    = int(tw * h2 / w2)\n",
    "            thumb = cv2.resize(vis, (tw,th), interpolation=cv2.INTER_AREA)\n",
    "            img_tk = ImageTk.PhotoImage(\n",
    "                        Image.fromarray(cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB)))\n",
    "            self.tk_imgs.append(img_tk)\n",
    "\n",
    "            x = pad + idx*(tw+pad)\n",
    "            y = pad\n",
    "            self.canvas.create_image(x, y, anchor='nw', image=img_tk)\n",
    "            self.canvas.create_text(x+tw//2, y+th+10,\n",
    "                                    text=var, font=(\"Helvetica\",8,\"bold\"))\n",
    "\n",
    "        self.master.master.title(\n",
    "            f\"{alg} Vectors — Img0→Img{self.index}/{len(self.images)-1}\"\n",
    "        )\n",
    "\n",
    "    def next_image(self):\n",
    "        if self.index < len(self.images)-1:\n",
    "            self.index += 1\n",
    "            self.show_flow()\n",
    "\n",
    "    def prev_image(self):\n",
    "        if self.index > 0:\n",
    "            self.index -= 1\n",
    "            self.show_flow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5d5dccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureRegistrationPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Feature-Based Registration\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b819fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearningRegistrationPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Deep Learning Registration\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "4e5ce13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModelPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Hybrid Model (Feature + Flow + Deep Learning)\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "2a76ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkingPage(Page):\n",
    "    def __init__(self, parent, **kwargs):\n",
    "        super().__init__(parent, **kwargs)\n",
    "        ttk.Label(self, text=\"Benchmarking Framework\", font=(\"Helvetica\", 18)).pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333502e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Main Application ===\n",
    "class MainApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"OCT Deformation Tracking Suite\")\n",
    "        self.geometry(\"1200x800\")\n",
    "        style = ttk.Style(self)\n",
    "        style.theme_use('clam')\n",
    "        style.configure('TNotebook.Tab', padding=(10, 10))\n",
    "\n",
    "        notebook = ttk.Notebook(self)\n",
    "        notebook.pack(fill='both', expand=True)\n",
    "\n",
    "        # Add pages to notebook\n",
    "        for PageClass, title in [\n",
    "            (HomePage, \"Home\"),\n",
    "            (PreprocessingPage, \"Preprocessing\"),\n",
    "            (OpticalFlowPage, \"Optical Flow\"),\n",
    "            (FeatureRegistrationPage, \"Feature Reg.\"),\n",
    "            (DeepLearningRegistrationPage, \"Deep Learning\"),\n",
    "            (HybridModelPage, \"Hybrid Model\"),\n",
    "            (BenchmarkingPage, \"Benchmarking\"),\n",
    "        ]:\n",
    "            page = PageClass(notebook)\n",
    "            notebook.add(page, text=title)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MainApp().mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
